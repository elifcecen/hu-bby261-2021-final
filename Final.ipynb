{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Makina.ipynb",
      "provenance": [],
      "mount_file_id": "1AtTOeojX5_KL05H7ss69RsnxJzBZoO1L",
      "authorship_tag": "ABX9TyOt6m8PPYjzrMoIXehBJiBU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elifcecen/hu-bby261-2021-final/blob/main/Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "id": "vUdRkP56PHO8",
        "outputId": "52b8b5fa-7fd4-4d1f-9bfb-ba07a7883cf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "Number of images in x_train 60000\n",
            "Number of images in x_test 10000\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 35s 18ms/step - loss: 0.2039 - accuracy: 0.9388\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 33s 18ms/step - loss: 0.0805 - accuracy: 0.9753\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0568 - accuracy: 0.9824\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 33s 18ms/step - loss: 0.0418 - accuracy: 0.9864\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0343 - accuracy: 0.9884\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0271 - accuracy: 0.9905\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 33s 18ms/step - loss: 0.0259 - accuracy: 0.9911\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 33s 18ms/step - loss: 0.0211 - accuracy: 0.9928\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 33s 18ms/step - loss: 0.0191 - accuracy: 0.9936\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 33s 18ms/step - loss: 0.0185 - accuracy: 0.9939\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0538 - accuracy: 0.9864\n",
            "7\n",
            "tahminEt:  [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "tahminSayı:  [3]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "image_index = 0 \n",
        "print(y_train[image_index]) \n",
        "plt.imshow(x_train[image_index], cmap='Greys')\n",
        "\n",
        "x_train.shape\n",
        "\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('Number of images in x_train', x_train.shape[0])\n",
        "print('Number of images in x_test', x_test.shape[0])\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation=tf.nn.relu))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10,activation=tf.nn.softmax))\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model.fit(x=x_train,y=y_train, epochs=10)\n",
        "\n",
        "model.evaluate(x_test, y_test)\n",
        "\n",
        "image_index = 0\n",
        "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
        "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
        "print(pred.argmax())\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "png = Image.open(\"/content/drive/MyDrive/resimler/çizim 6.png\").convert (\"L\")\n",
        "png = np.resize(png, (28, 28, 1))\n",
        "pngBinary = np.array(png)\n",
        "plt.imshow(pngBinary.reshape(28, 28))\n",
        "\n",
        "tahminEt = model.predict(pngBinary.reshape(1, 28, 28, 1))\n",
        "\n",
        "tahminSayı = np.argmax(model.predict(pngBinary.reshape(1, 28, 28, 1)), axis=-1)\n",
        "\n",
        "\n",
        "print(\"tahminEt: \", tahminEt)\n",
        "print(\"tahminSayı: \", tahminSayı)"
      ]
    }
  ]
}